{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-gradcam\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "class Classification(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Classification, self).__init__()\n",
    "        self.backbone = models.resnet50()\n",
    "        self.backbone.fc = nn.Linear(self.backbone.fc.in_features, 2)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        out = self.backbone(x)\n",
    "\n",
    "# Instantiate your model\n",
    "model = Classification()\n",
    "        \n",
    "_ = model.load_state_dict(torch.load('./resnet50_pretrain.pth') , strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Directory containing all images\n",
    "image_dir = './Dataset/'\n",
    "\n",
    "# Read all the file names\n",
    "all_images = os.listdir(image_dir)\n",
    "\n",
    "# Split the file names into train and test\n",
    "train_images, test_images = train_test_split(all_images, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Total {len(all_images)} images split into {len(train_images)} training and {len(test_images)} test images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Directories for train and test images\n",
    "train_dir = './train_directory/'\n",
    "test_dir = './test_directory/'\n",
    "\n",
    "# Move the images\n",
    "for img in train_images:\n",
    "    shutil.move(image_dir + img, train_dir + img)\n",
    "\n",
    "for img in test_images:\n",
    "    shutil.move(image_dir + img, test_dir + img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, directory, transform=None):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.file_list = os.listdir(directory)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_list[idx]\n",
    "        image_path = os.path.join(self.directory, file_name)\n",
    "\n",
    "        # Load image\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # Apply transformations to the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Set label based on filename\n",
    "        if 'abnormal' in file_name:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Define your datasets\n",
    "train_dataset = CustomDataset(train_dir, transform=transform)\n",
    "\n",
    "\n",
    "# Define your dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "val_dataset = CustomDataset(test_dir, transform=transform)\n",
    "\n",
    "\n",
    "# Define your validation dataloaders\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#\n",
    "best_f1 = 0.0\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()  # set the model to training mode\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print (f'Train Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_dataloader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()  # set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "        for inputs, labels in val_dataloader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_labels.extend(labels)\n",
    "            all_predictions.extend(predicted)\n",
    "\n",
    "        # Convert lists to tensors for metrics calculation\n",
    "        all_labels = torch.stack(all_labels).to('cpu')\n",
    "        all_predictions = torch.stack(all_predictions).to('cpu')\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(all_labels, all_predictions)\n",
    "        precision = precision_score(all_labels, all_predictions, average='weighted')\n",
    "        recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "        f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "\n",
    "        print(f'Val Epoch [{epoch+1}/{num_epochs}], Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}')\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            torch.jit.save(torch.jit.script(model), 'cls_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of data\n",
    "data, _ = next(iter(train_dataloader))\n",
    "\n",
    "# Select the first image from the batch\n",
    "data = data[0].unsqueeze(0)\n",
    "\n",
    "# Ensure the data is on the right device\n",
    "data = data.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradcam.utils import visualize_cam\n",
    "from gradcam import GradCAM, GradCAMpp\n",
    "\n",
    "# Suppose `model` is your trained model and `data` is your input data\n",
    "model.eval()\n",
    "\n",
    "# Define GradCAM and GradCAM++\n",
    "gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "gradcam_pp = GradCAMpp.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "\n",
    "# Get the GradCAM mask\n",
    "mask, _ = gradcam(data)\n",
    "mask_pp, _ = gradcam_pp(data)\n",
    "\n",
    "# Visualize the GradCAM and GradCAM++ masks\n",
    "heatmap, result = visualize_cam(mask, data)\n",
    "heatmap_pp, result_pp = visualize_cam(mask_pp, data)\n",
    "\n",
    "# Save results\n",
    "cv2.imwrite('gradcam.jpg', result)\n",
    "cv2.imwrite('gradcam_pp.jpg', result_pp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
